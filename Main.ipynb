{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/194 [00:00<?, ?it/s]\n",
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arthur\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\arthur\\Anaconda3\\lib\\site-packages\\tqdm\\_tqdm.py\", line 148, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"C:\\Users\\arthur\\Anaconda3\\lib\\_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already droped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏                                      | 1/194 [01:43<5:31:31, 103.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already droped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 194/194 [6:08:57<00:00, 114.11s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "root_path = \"csv/traffic\"\n",
    "drop = ['samples_below_100pct_ff', 'samples_below_95pct_ff', 'samples_below_90pct_ff', 'samples_below_80pct_ff.1',\n",
    "          'samples_below_80pct_ff', 'samples_below_75pct_ff', 'samples_below_70pct_ff', 'samples_below_65pct_ff',\n",
    "          'samples_below_60pct_ff', 'samples_below_55pct_ff', 'samples_below_50pct_ff', 'samples_below_45pct_ff',\n",
    "          'samples_below_40pct_ff', 'samples_below_35pct_ff', 'samples_below_30pct_ff', 'samples_below_25pct_ff',\n",
    "          'samples_below_20pct_ff', 'samples_below_15pct_ff', 'samples_below_10pct_ff', 'samples_below_5pct_ff']\n",
    "\n",
    "\n",
    "files = os.listdir(root_path)\n",
    "for f in tqdm(files):\n",
    "    df = pd.read_csv('{}/{}'.format(root_path, f))\n",
    "    try:\n",
    "        df.drop(columns=drop, inplace=True)\n",
    "        df.to_csv('{}/{}'.format(root_path, f))\n",
    "    except ValueError:\n",
    "        print('Already droped')  ...................................-      \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    2.017846e+06\n",
      "mean     1.008922e+06\n",
      "std      5.825021e+05\n",
      "min      0.000000e+00\n",
      "25%      5.044612e+05\n",
      "50%      1.008922e+06\n",
      "75%      1.513384e+06\n",
      "max      2.017845e+06\n",
      "Name: Unnamed: 0, dtype: float64\n",
      "----------\n",
      "count                 2017846\n",
      "unique                    288\n",
      "top       03/03/2018 21:10:00\n",
      "freq                     9576\n",
      "Name: utc_time_id, dtype: object\n",
      "----------\n",
      "count     2017846\n",
      "unique          2\n",
      "top           tmc\n",
      "freq      1609313\n",
      "Name: source_ref, dtype: object\n",
      "----------\n",
      "count       2017846\n",
      "unique        30141\n",
      "top       106+23194\n",
      "freq            288\n",
      "Name: source_id, dtype: object\n",
      "----------\n",
      "count       2017846\n",
      "unique            1\n",
      "top       hereA0106\n",
      "freq        2017846\n",
      "Name: feed_id, dtype: object\n",
      "----------\n",
      "count    2.017846e+06\n",
      "mean     9.866922e-01\n",
      "std      1.145891e-01\n",
      "min      0.000000e+00\n",
      "25%      1.000000e+00\n",
      "50%      1.000000e+00\n",
      "75%      1.000000e+00\n",
      "max      1.000000e+00\n",
      "Name: primary_link_source_flag, dtype: float64\n",
      "----------\n",
      "count    2.017846e+06\n",
      "mean     5.000703e+00\n",
      "std      5.958459e-02\n",
      "min      3.000000e+00\n",
      "25%      5.000000e+00\n",
      "50%      5.000000e+00\n",
      "75%      5.000000e+00\n",
      "max      1.000000e+01\n",
      "Name: samples, dtype: float64\n",
      "----------\n",
      "count    2.012521e+06\n",
      "mean     5.599094e+01\n",
      "std      2.462219e+01\n",
      "min      3.310000e+00\n",
      "25%      3.753000e+01\n",
      "50%      5.058000e+01\n",
      "75%      7.092000e+01\n",
      "max      1.299900e+02\n",
      "Name: avg_speed, dtype: float64\n",
      "----------\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: avg_flow, dtype: float64\n",
      "----------\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: avg_occ, dtype: float64\n",
      "----------\n",
      "count    2.017846e+06\n",
      "mean     6.516734e+01\n",
      "std      2.182340e+01\n",
      "min      1.400000e+01\n",
      "25%      4.921000e+01\n",
      "50%      5.986000e+01\n",
      "75%      7.702000e+01\n",
      "max      1.140100e+02\n",
      "Name: avg_freeflow_speed, dtype: float64\n",
      "----------\n",
      "count    2.012521e+06\n",
      "mean     1.790117e+00\n",
      "std      2.740035e+00\n",
      "min      0.000000e+00\n",
      "25%      2.500000e-01\n",
      "50%      1.120000e+00\n",
      "75%      2.270000e+00\n",
      "max      8.600000e+01\n",
      "Name: avg_travel_time, dtype: float64\n",
      "----------\n",
      "count    2.017846e+06\n",
      "mean     8.713955e-01\n",
      "std      1.789200e+00\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.000000e+01\n",
      "Name: high_quality_samples, dtype: float64\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    print(df[col].describe())\n",
    "    print('----------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column analyzing\n",
    "Analyzing each columns in the data frame, it turned clear that only 3 columns is from our interrest: **utc_time_id, source_id and avg_speed**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## source_id\n",
    "\n",
    "The column source_id give us 30141 unique values, refering to 30141 diferrent measurement points through the city in question(San Francisco), futher our dataframe will have the dimensionalite of ** [N, 30141]**, where N is the number of samples, and each column contains the avg_speed of a specific measurement point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>utc_time_id</th>\n",
       "      <th>source_ref</th>\n",
       "      <th>source_id</th>\n",
       "      <th>feed_id</th>\n",
       "      <th>primary_link_source_flag</th>\n",
       "      <th>samples</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>avg_flow</th>\n",
       "      <th>avg_occ</th>\n",
       "      <th>avg_freeflow_speed</th>\n",
       "      <th>avg_travel_time</th>\n",
       "      <th>high_quality_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>03/03/2018 07:30:00</td>\n",
       "      <td>tmc</td>\n",
       "      <td>106-13503</td>\n",
       "      <td>hereA0106</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>49.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>03/03/2018 07:35:00</td>\n",
       "      <td>tmc</td>\n",
       "      <td>106-13503</td>\n",
       "      <td>hereA0106</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>03/03/2018 07:40:00</td>\n",
       "      <td>tmc</td>\n",
       "      <td>106-13503</td>\n",
       "      <td>hereA0106</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>03/03/2018 07:45:00</td>\n",
       "      <td>tmc</td>\n",
       "      <td>106-13503</td>\n",
       "      <td>hereA0106</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>03/03/2018 07:50:00</td>\n",
       "      <td>tmc</td>\n",
       "      <td>106-13503</td>\n",
       "      <td>hereA0106</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          utc_time_id source_ref  source_id    feed_id  \\\n",
       "0           0  03/03/2018 07:30:00        tmc  106-13503  hereA0106   \n",
       "1           1  03/03/2018 07:35:00        tmc  106-13503  hereA0106   \n",
       "2           2  03/03/2018 07:40:00        tmc  106-13503  hereA0106   \n",
       "3           3  03/03/2018 07:45:00        tmc  106-13503  hereA0106   \n",
       "4           4  03/03/2018 07:50:00        tmc  106-13503  hereA0106   \n",
       "\n",
       "   primary_link_source_flag  samples  avg_speed  avg_flow  avg_occ  \\\n",
       "0                         1        5       49.8       NaN      NaN   \n",
       "1                         1        5       50.0       NaN      NaN   \n",
       "2                         1        5       50.0       NaN      NaN   \n",
       "3                         1        5       50.0       NaN      NaN   \n",
       "4                         1        5       50.0       NaN      NaN   \n",
       "\n",
       "   avg_freeflow_speed  avg_travel_time  high_quality_samples  \n",
       "0                50.0             0.96                     0  \n",
       "1                50.0             0.96                     0  \n",
       "2                50.0             0.96                     0  \n",
       "3                50.0             0.96                     0  \n",
       "4                50.0             0.96                     0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time column\n",
    "The time utc_time_column is in string format, not in datetime format, it is needed to convert for easier use in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/194 [00:00<?, ?it/s]\n",
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arthur\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\arthur\\Anaconda3\\lib\\site-packages\\tqdm\\_tqdm.py\", line 148, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"C:\\Users\\arthur\\Anaconda3\\lib\\_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "100%|█████████████████████████████████████| 194/194 [5:49:40<00:00, 108.15s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for f in tqdm(files):\n",
    "    df = pd.read_csv('{}/{}'.format(root_path, f))\n",
    "    df = df[['utc_time_id', 'source_id', 'avg_speed']]\n",
    "    df['utc_time_id'] = pd.to_datetime(df['utc_time_id'], infer_datetime_format=True)\n",
    "    df.to_csv('{}/{}'.format(root_path, f), index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File manager\n",
    "\n",
    "Due the high volume of information that needs to be process, we will create a way to process the data in multiprocess and in diferents computers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "from queue import Queue\n",
    "import random\n",
    "\n",
    "class FileManager(object):\n",
    "    def __init__(self, directory = 'csv/traffic', path = 'C:/Users/arthur/Dropbox/TrafficFlow/lista.pkl'):\n",
    "\n",
    "        self.files = os.listdir(directory)\n",
    "        self.done = []\n",
    "        self.processing = []\n",
    "        self.path = path\n",
    "        \n",
    "    def get_item(self):\n",
    "        x = self.files.pop(random.randint(0,len(self.files)-1))\n",
    "        self.processing.append(x)\n",
    "        save_pkl(self, self.path)\n",
    "        return x\n",
    "    def finnish(self, x):\n",
    "        self.processing.remove(x)\n",
    "        self.done.append(x)\n",
    "        save_pkl(self, self.path)\n",
    "        \n",
    "    def set_path(self, path):\n",
    "        self.path = path\n",
    "        \n",
    "    def __str__(self):\n",
    "        msg = '{} itens to be process \\n {} itens processed'.format(len(self.files), len(self.processing) + len(self.done))\n",
    "        return msg\n",
    "    \n",
    "def save_pkl(obj, path = 'C:/Users/arthur/Dropbox/TrafficFlow/lista.pkl'):\n",
    "    pkl.dump(obj, open(path, 'wb'))\n",
    "    \n",
    "def load_pkl(path = 'C:/Users/arthur/Dropbox/TrafficFlow/lista.pkl'):\n",
    "    obj = pkl.load(open(path, 'rb'))\n",
    "    if len(obj.processing) > 0:\n",
    "        print('The process was stoped with running process')\n",
    "        print('Restoring process to process queue')\n",
    "        obj.files += obj.processing\n",
    "        obj.processing = []\n",
    "    return obj\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropdox_path = 'C:/Users/arthur/Dropbox/TrafficFlow/lista.pkl'\n",
    "dir_path = 'csv/traffic'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_date(file):\n",
    "    name, ext = file.rsplit('.')\n",
    "    return name[-10:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess(file):\n",
    "    df = pd.read_csv(file, dtype={'source_id':'category'})\n",
    "    path = 'csv/traffic/{}.csv'.format(get_date(file))\n",
    "    print(path)\n",
    "    df_res = df.pivot(index='utc_time_id', columns='source_id', values='avg_speed')\n",
    "    df_res.to_csv(path, index=True)\n",
    "    return file\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Task(object):\n",
    "    def __init__(self, file, user, status):\n",
    "        self.file = file\n",
    "        self.user = user\n",
    "        self.status = status \n",
    "        \n",
    "\n",
    "    def get_file(self):\n",
    "        self.status = 'running'\n",
    "        return self.file\n",
    "        \n",
    "    def __str__(self):\n",
    "        return '{} - {}'.format(self.user, self.file)\n",
    "        \n",
    "def get_status(obj):\n",
    "    arthur_count = 0\n",
    "    zaroni_count = 0\n",
    "    tony_count = 0\n",
    "    total = len(obj)\n",
    "    for task in obj:\n",
    "        if task.status == 'done':\n",
    "            if task.user == 'arthur':\n",
    "                arthur_count += 1\n",
    "            elif task.user == 'zaroni':\n",
    "                zaroni_count += 1\n",
    "            else:\n",
    "                tony_count += 1\n",
    "    print('Arthur converted {}'.format(arthur_count))\n",
    "    print('Zaroni converted {}'.format(zaroni_count))\n",
    "    print('Tony converted {}'.format(tony_count))\n",
    "    print('{} still missing'.format(total - arthur_count - zaroni_count - tony_count))\n",
    "    print('Progress: {}/{}'.format((arthur_count+zaroni_count+tony_count),total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle as pkl \n",
    "direc = os.listdir(dir_path)\n",
    "\n",
    "create = False\n",
    "\n",
    "if create:\n",
    "    len_ = len(direc)\n",
    "    lista = []\n",
    "    for i, element in enumerate(direc):\n",
    "        if i < len_/3:\n",
    "            lista.append(Task('{}/{}'.format(dir_path, element), 'arthur', 'raw'))\n",
    "        elif i < len_*2/3:\n",
    "            lista.append(Task(element, 'Zaroni', 'raw'))\n",
    "        else:\n",
    "            lista.append(Task(element, 'Tony', 'raw'))\n",
    "\n",
    "    pkl.dump(lista, open(dropdox_path, 'wb'))\n",
    "else:\n",
    "    lista = pkl.load(open(dropdox_path, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_11_22.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "53it [00:43,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_11_23.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "54it [01:03,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_11_24.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "55it [01:30,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_11_25.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "56it [01:55,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_11_26.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "57it [02:15,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_11_27.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "58it [02:58,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_11_28.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "59it [03:41,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_11_29.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "60it [04:23,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_11_30.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "61it [05:07,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_12_01.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "62it [05:53,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_12_02.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "63it [06:24,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_12_03.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "64it [06:48,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_12_04.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "65it [07:35,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_12_05.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "66it [08:23,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_12_06.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "67it [09:08,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_12_07.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "68it [09:56,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_12_08.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "69it [10:44,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_12_09.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "70it [11:16,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_12_10.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "71it [11:40,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/traffic/2017_12_11.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [12:25,  4.84s/it]\n"
     ]
    }
   ],
   "source": [
    "user = 'arthur'\n",
    "\n",
    "\n",
    "for i,l in tqdm(enumerate(lista)):\n",
    "    if i > 51 and i < 72: \n",
    "        files_converted = preprocess(l.get_file())\n",
    "        l.status = 'done'\n",
    "        pkl.dump(lista, open(dropdox_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_01.csv done arthur\n",
      "1 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_02.csv done arthur\n",
      "2 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_03.csv done arthur\n",
      "3 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_04.csv done arthur\n",
      "4 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_05.csv done arthur\n",
      "5 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_06.csv done arthur\n",
      "6 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_07.csv done arthur\n",
      "7 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_08.csv done arthur\n",
      "8 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_09.csv done arthur\n",
      "9 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_10.csv done arthur\n",
      "10 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_11.csv done arthur\n",
      "11 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_12.csv done arthur\n",
      "12 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_13.csv done arthur\n",
      "13 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_14.csv done arthur\n",
      "14 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_15.csv done arthur\n",
      "15 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_16.csv done arthur\n",
      "16 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_17.csv done arthur\n",
      "17 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_18.csv done arthur\n",
      "18 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_19.csv done arthur\n",
      "19 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_20.csv done arthur\n",
      "20 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_21.csv done arthur\n",
      "21 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_22.csv done arthur\n",
      "22 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_23.csv done arthur\n",
      "23 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_24.csv done arthur\n",
      "24 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_25.csv done arthur\n",
      "25 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_26.csv done arthur\n",
      "26 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_27.csv done arthur\n",
      "27 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_28.csv done arthur\n",
      "28 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_29.csv done arthur\n",
      "29 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_30.csv done arthur\n",
      "30 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_10_31.csv done arthur\n",
      "31 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_01.csv done arthur\n",
      "32 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_02.csv done arthur\n",
      "33 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_03.csv done arthur\n",
      "34 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_04.csv done arthur\n",
      "35 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_05.csv done arthur\n",
      "36 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_06.csv done arthur\n",
      "37 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_07.csv done arthur\n",
      "38 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_08.csv done arthur\n",
      "39 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_09.csv done arthur\n",
      "40 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_10.csv done arthur\n",
      "41 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_11.csv done arthur\n",
      "42 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_12.csv done arthur\n",
      "43 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_13.csv done arthur\n",
      "44 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_14.csv done arthur\n",
      "45 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_15.csv done arthur\n",
      "46 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_16.csv done arthur\n",
      "47 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_17.csv done arthur\n",
      "48 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_18.csv done arthur\n",
      "49 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_19.csv done arthur\n",
      "50 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_20.csv done arthur\n",
      "51 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_21.csv done arthur\n",
      "52 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_22.csv done Zaroni\n",
      "53 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_23.csv done Zaroni\n",
      "54 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_24.csv done Zaroni\n",
      "55 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_25.csv done Zaroni\n",
      "56 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_26.csv done Zaroni\n",
      "57 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_27.csv done Zaroni\n",
      "58 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_28.csv done Zaroni\n",
      "59 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_29.csv done Zaroni\n",
      "60 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_11_30.csv done Zaroni\n",
      "61 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_01.csv done Zaroni\n",
      "62 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_02.csv done Zaroni\n",
      "63 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_03.csv done Zaroni\n",
      "64 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_04.csv done Zaroni\n",
      "65 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_05.csv done Zaroni\n",
      "66 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_06.csv done Zaroni\n",
      "67 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_07.csv done Zaroni\n",
      "68 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_08.csv done Zaroni\n",
      "69 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_09.csv done Zaroni\n",
      "70 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_10.csv done Zaroni\n",
      "71 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_11.csv done Zaroni\n",
      "72 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_12.csv done Zaroni\n",
      "73 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_13.csv done Zaroni\n",
      "74 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_14.csv done Zaroni\n",
      "75 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_15.csv done Zaroni\n",
      "76 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_16.csv done Zaroni\n",
      "77 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_17.csv done Zaroni\n",
      "78 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_18.csv done Zaroni\n",
      "79 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_19.csv done Zaroni\n",
      "80 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_20.csv done Zaroni\n",
      "81 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_21.csv done Zaroni\n",
      "82 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_22.csv done Zaroni\n",
      "83 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_23.csv done Zaroni\n",
      "84 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_24.csv done Zaroni\n",
      "85 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_25.csv done Zaroni\n",
      "86 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_26.csv done Zaroni\n",
      "87 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_27.csv done Zaroni\n",
      "88 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_28.csv done Zaroni\n",
      "89 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_29.csv done Zaroni\n",
      "90 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_30.csv done Zaroni\n",
      "91 csv/traffic/contracted-Caltrans_text_gn_link_5min_2017_12_31.csv done Zaroni\n",
      "92 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_01.csv done Zaroni\n",
      "93 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_02.csv done Zaroni\n",
      "94 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_03.csv done Zaroni\n",
      "95 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_04.csv done Zaroni\n",
      "96 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_05.csv done Zaroni\n",
      "97 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_06.csv done Zaroni\n",
      "98 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_07.csv done Zaroni\n",
      "99 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_08.csv done Zaroni\n",
      "100 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_09.csv done Zaroni\n",
      "101 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_10.csv done Zaroni\n",
      "102 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_11.csv done Zaroni\n",
      "103 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_12.csv done Tony\n",
      "104 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_13.csv done Tony\n",
      "105 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_14.csv done Tony\n",
      "106 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_15.csv done Tony\n",
      "107 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_16.csv done Tony\n",
      "108 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_17.csv done Tony\n",
      "109 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_18.csv done Tony\n",
      "110 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_19.csv done Tony\n",
      "111 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_20.csv done Tony\n",
      "112 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_21.csv done Tony\n",
      "113 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_22.csv done Tony\n",
      "114 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_23.csv done Tony\n",
      "115 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_24.csv done Tony\n",
      "116 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_25.csv done Tony\n",
      "117 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_26.csv done Tony\n",
      "118 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_27.csv done Tony\n",
      "119 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_28.csv done Tony\n",
      "120 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_29.csv done Tony\n",
      "121 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_30.csv done Tony\n",
      "122 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_01_31.csv done Tony\n",
      "123 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_01.csv done Tony\n",
      "124 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_02.csv done Tony\n",
      "125 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_03.csv done Tony\n",
      "126 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_04.csv done Tony\n",
      "127 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_05.csv done Tony\n",
      "128 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_06.csv done Tony\n",
      "129 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_07.csv done Tony\n",
      "130 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_08.csv done Tony\n",
      "131 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_09.csv done Tony\n",
      "132 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_10.csv done Tony\n",
      "133 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_11.csv done Tony\n",
      "134 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_12.csv done Tony\n",
      "135 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_13.csv done Tony\n",
      "136 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_14.csv done Tony\n",
      "137 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_15.csv done Tony\n",
      "138 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_16.csv done Tony\n",
      "139 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_17.csv done Tony\n",
      "140 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_18.csv done Tony\n",
      "141 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_19.csv done Tony\n",
      "142 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_20.csv done Tony\n",
      "143 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_21.csv done Tony\n",
      "144 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_22.csv done Tony\n",
      "145 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_23.csv done Tony\n",
      "146 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_24.csv done Tony\n",
      "147 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_25.csv done Tony\n",
      "148 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_26.csv done Tony\n",
      "149 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_27.csv done Tony\n",
      "150 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_02_28.csv done Tony\n",
      "151 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_03_01.csv done Tony\n",
      "152 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_03_02.csv done Tony\n",
      "153 csv/traffic/contracted-Caltrans_text_gn_link_5min_2018_03_03.csv done Tony\n"
     ]
    }
   ],
   "source": [
    "for i, l in enumerate(lista):\n",
    "    print(l.file, l.status, l.user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'csv/traffic'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file, dtype={'source_id':'category'})\n",
    "path = 'csv/traffic/{}.csv'.format(get_date(file))\n",
    "print(path)\n",
    "df_res = df.pivot(index='utc_time_id', columns='source_id', values='avg_speed')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'csv/traffic'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
